{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "prime-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, log_loss, f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "chubby-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url_train = \"https://raw.githubusercontent.com/RTheophile/td_ml_ynov/main/data/train.csv\"\n",
    "url_test = \"https://raw.githubusercontent.com/RTheophile/td_ml_ynov/main/data/test.csv\"\n",
    "\n",
    "df_train = pd.read_csv(url_train, sep=',', decimal='.' )\n",
    "df_test = pd.read_csv(url_test, sep=',', decimal='.' )\n",
    "test_id=df_test['music_id'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "satisfied-breed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>music_id</th>\n",
       "      <th>chroma_0_mean</th>\n",
       "      <th>chroma_0_std</th>\n",
       "      <th>chroma_10_mean</th>\n",
       "      <th>chroma_10_std</th>\n",
       "      <th>chroma_11_mean</th>\n",
       "      <th>chroma_11_std</th>\n",
       "      <th>chroma_1_mean</th>\n",
       "      <th>chroma_1_std</th>\n",
       "      <th>chroma_2_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_9_std</th>\n",
       "      <th>onset_rate</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_decrease_mean</th>\n",
       "      <th>spectral_flux_mean</th>\n",
       "      <th>spectral_rolloff_mean</th>\n",
       "      <th>spectral_spread_mean</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>zcr_std</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>866.507629</td>\n",
       "      <td>1585.437134</td>\n",
       "      <td>415.300842</td>\n",
       "      <td>710.790771</td>\n",
       "      <td>683.865845</td>\n",
       "      <td>1011.552856</td>\n",
       "      <td>473.484100</td>\n",
       "      <td>744.247925</td>\n",
       "      <td>304.914825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647313</td>\n",
       "      <td>3.631719</td>\n",
       "      <td>27.621587</td>\n",
       "      <td>-0.186330</td>\n",
       "      <td>1.962404</td>\n",
       "      <td>1525.877193</td>\n",
       "      <td>1579.021838</td>\n",
       "      <td>190.907164</td>\n",
       "      <td>149.482276</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>832.956909</td>\n",
       "      <td>2140.568115</td>\n",
       "      <td>287.584564</td>\n",
       "      <td>281.795380</td>\n",
       "      <td>405.467224</td>\n",
       "      <td>754.076904</td>\n",
       "      <td>1061.359863</td>\n",
       "      <td>2263.894531</td>\n",
       "      <td>2502.509033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575588</td>\n",
       "      <td>6.230564</td>\n",
       "      <td>38.780628</td>\n",
       "      <td>-0.013198</td>\n",
       "      <td>2.139456</td>\n",
       "      <td>1740.789474</td>\n",
       "      <td>1941.791036</td>\n",
       "      <td>257.913214</td>\n",
       "      <td>171.257592</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>331.544586</td>\n",
       "      <td>553.657532</td>\n",
       "      <td>260.467499</td>\n",
       "      <td>327.618225</td>\n",
       "      <td>283.580139</td>\n",
       "      <td>312.385986</td>\n",
       "      <td>204.369690</td>\n",
       "      <td>225.922531</td>\n",
       "      <td>286.470215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.837297</td>\n",
       "      <td>4.264771</td>\n",
       "      <td>86.371120</td>\n",
       "      <td>-0.155013</td>\n",
       "      <td>1.336048</td>\n",
       "      <td>5243.859649</td>\n",
       "      <td>15422.032531</td>\n",
       "      <td>508.122337</td>\n",
       "      <td>296.141124</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>454.521851</td>\n",
       "      <td>1170.188110</td>\n",
       "      <td>601.021790</td>\n",
       "      <td>1035.021240</td>\n",
       "      <td>721.523865</td>\n",
       "      <td>1861.131836</td>\n",
       "      <td>350.991791</td>\n",
       "      <td>495.942383</td>\n",
       "      <td>432.551971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702976</td>\n",
       "      <td>4.064860</td>\n",
       "      <td>16.844325</td>\n",
       "      <td>-0.287745</td>\n",
       "      <td>2.207420</td>\n",
       "      <td>988.596491</td>\n",
       "      <td>999.051613</td>\n",
       "      <td>144.638374</td>\n",
       "      <td>142.303996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>180.331635</td>\n",
       "      <td>245.818512</td>\n",
       "      <td>388.924744</td>\n",
       "      <td>917.082581</td>\n",
       "      <td>186.856262</td>\n",
       "      <td>192.765305</td>\n",
       "      <td>212.240402</td>\n",
       "      <td>370.108063</td>\n",
       "      <td>170.875610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.487534</td>\n",
       "      <td>4.164816</td>\n",
       "      <td>5.764473</td>\n",
       "      <td>-0.626706</td>\n",
       "      <td>1.263404</td>\n",
       "      <td>21.491228</td>\n",
       "      <td>735.051431</td>\n",
       "      <td>181.818928</td>\n",
       "      <td>106.604597</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   music_id  chroma_0_mean  chroma_0_std  chroma_10_mean  chroma_10_std  \\\n",
       "0         0     866.507629   1585.437134      415.300842     710.790771   \n",
       "1         1     832.956909   2140.568115      287.584564     281.795380   \n",
       "2         2     331.544586    553.657532      260.467499     327.618225   \n",
       "3         3     454.521851   1170.188110      601.021790    1035.021240   \n",
       "4         4     180.331635    245.818512      388.924744     917.082581   \n",
       "\n",
       "   chroma_11_mean  chroma_11_std  chroma_1_mean  chroma_1_std  chroma_2_mean  \\\n",
       "0      683.865845    1011.552856     473.484100    744.247925     304.914825   \n",
       "1      405.467224     754.076904    1061.359863   2263.894531    2502.509033   \n",
       "2      283.580139     312.385986     204.369690    225.922531     286.470215   \n",
       "3      721.523865    1861.131836     350.991791    495.942383     432.551971   \n",
       "4      186.856262     192.765305     212.240402    370.108063     170.875610   \n",
       "\n",
       "   ...  mfcc_9_std  onset_rate  spectral_centroid_mean  \\\n",
       "0  ...    0.647313    3.631719               27.621587   \n",
       "1  ...    0.575588    6.230564               38.780628   \n",
       "2  ...    0.837297    4.264771               86.371120   \n",
       "3  ...    0.702976    4.064860               16.844325   \n",
       "4  ...    0.487534    4.164816                5.764473   \n",
       "\n",
       "   spectral_decrease_mean  spectral_flux_mean  spectral_rolloff_mean  \\\n",
       "0               -0.186330            1.962404            1525.877193   \n",
       "1               -0.013198            2.139456            1740.789474   \n",
       "2               -0.155013            1.336048            5243.859649   \n",
       "3               -0.287745            2.207420             988.596491   \n",
       "4               -0.626706            1.263404              21.491228   \n",
       "\n",
       "   spectral_spread_mean    zcr_mean     zcr_std  category  \n",
       "0           1579.021838  190.907164  149.482276         1  \n",
       "1           1941.791036  257.913214  171.257592         3  \n",
       "2          15422.032531  508.122337  296.141124         3  \n",
       "3            999.051613  144.638374  142.303996         1  \n",
       "4            735.051431  181.818928  106.604597         1  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "vertical-porcelain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>music_id</th>\n",
       "      <th>chroma_0_mean</th>\n",
       "      <th>chroma_0_std</th>\n",
       "      <th>chroma_10_mean</th>\n",
       "      <th>chroma_10_std</th>\n",
       "      <th>chroma_11_mean</th>\n",
       "      <th>chroma_11_std</th>\n",
       "      <th>chroma_1_mean</th>\n",
       "      <th>chroma_1_std</th>\n",
       "      <th>chroma_2_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_9_std</th>\n",
       "      <th>onset_rate</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_decrease_mean</th>\n",
       "      <th>spectral_flux_mean</th>\n",
       "      <th>spectral_rolloff_mean</th>\n",
       "      <th>spectral_spread_mean</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>zcr_std</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>320.000000</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>319.000000</td>\n",
       "      <td>316.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>319.000000</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>316.000000</td>\n",
       "      <td>316.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>316.000000</td>\n",
       "      <td>316.000000</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>320.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>159.500000</td>\n",
       "      <td>461.223799</td>\n",
       "      <td>727.558402</td>\n",
       "      <td>441.424764</td>\n",
       "      <td>664.515463</td>\n",
       "      <td>420.808596</td>\n",
       "      <td>606.042905</td>\n",
       "      <td>417.116685</td>\n",
       "      <td>605.835885</td>\n",
       "      <td>469.942682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.629552</td>\n",
       "      <td>4.917406</td>\n",
       "      <td>28.050904</td>\n",
       "      <td>-0.155241</td>\n",
       "      <td>1.737679</td>\n",
       "      <td>1180.002741</td>\n",
       "      <td>1942.502831</td>\n",
       "      <td>192.060511</td>\n",
       "      <td>115.472340</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>92.520268</td>\n",
       "      <td>302.890638</td>\n",
       "      <td>511.932682</td>\n",
       "      <td>286.127709</td>\n",
       "      <td>507.650090</td>\n",
       "      <td>284.887311</td>\n",
       "      <td>443.484753</td>\n",
       "      <td>269.444492</td>\n",
       "      <td>410.002545</td>\n",
       "      <td>319.000592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170709</td>\n",
       "      <td>2.537782</td>\n",
       "      <td>16.103779</td>\n",
       "      <td>0.185176</td>\n",
       "      <td>1.063592</td>\n",
       "      <td>711.314460</td>\n",
       "      <td>1984.500644</td>\n",
       "      <td>107.853027</td>\n",
       "      <td>53.495612</td>\n",
       "      <td>1.119785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.542076</td>\n",
       "      <td>108.190132</td>\n",
       "      <td>66.789970</td>\n",
       "      <td>129.553772</td>\n",
       "      <td>64.062683</td>\n",
       "      <td>117.359634</td>\n",
       "      <td>50.826832</td>\n",
       "      <td>93.769897</td>\n",
       "      <td>50.655052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405036</td>\n",
       "      <td>0.366504</td>\n",
       "      <td>1.656318</td>\n",
       "      <td>-0.650820</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>21.491228</td>\n",
       "      <td>41.709451</td>\n",
       "      <td>35.199924</td>\n",
       "      <td>32.996641</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>79.750000</td>\n",
       "      <td>254.774170</td>\n",
       "      <td>388.372406</td>\n",
       "      <td>248.708359</td>\n",
       "      <td>350.873505</td>\n",
       "      <td>231.128601</td>\n",
       "      <td>344.294373</td>\n",
       "      <td>228.390095</td>\n",
       "      <td>353.000809</td>\n",
       "      <td>258.015579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515947</td>\n",
       "      <td>3.048645</td>\n",
       "      <td>16.354873</td>\n",
       "      <td>-0.287891</td>\n",
       "      <td>0.958037</td>\n",
       "      <td>687.719298</td>\n",
       "      <td>626.473435</td>\n",
       "      <td>114.992507</td>\n",
       "      <td>78.780289</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>159.500000</td>\n",
       "      <td>377.393036</td>\n",
       "      <td>571.490845</td>\n",
       "      <td>381.081177</td>\n",
       "      <td>534.109131</td>\n",
       "      <td>340.970337</td>\n",
       "      <td>484.871140</td>\n",
       "      <td>354.934341</td>\n",
       "      <td>505.056274</td>\n",
       "      <td>403.037384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583850</td>\n",
       "      <td>4.731231</td>\n",
       "      <td>24.205491</td>\n",
       "      <td>-0.086321</td>\n",
       "      <td>1.461911</td>\n",
       "      <td>1020.833333</td>\n",
       "      <td>1274.624056</td>\n",
       "      <td>167.636659</td>\n",
       "      <td>104.338107</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>239.250000</td>\n",
       "      <td>592.239685</td>\n",
       "      <td>910.419189</td>\n",
       "      <td>558.673584</td>\n",
       "      <td>803.034241</td>\n",
       "      <td>506.674622</td>\n",
       "      <td>752.747421</td>\n",
       "      <td>507.147308</td>\n",
       "      <td>702.858398</td>\n",
       "      <td>568.195679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683956</td>\n",
       "      <td>6.615188</td>\n",
       "      <td>37.958948</td>\n",
       "      <td>0.002296</td>\n",
       "      <td>2.144044</td>\n",
       "      <td>1552.741228</td>\n",
       "      <td>2634.940367</td>\n",
       "      <td>240.335595</td>\n",
       "      <td>142.303996</td>\n",
       "      <td>2.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>319.000000</td>\n",
       "      <td>1643.472900</td>\n",
       "      <td>3421.152100</td>\n",
       "      <td>2172.719482</td>\n",
       "      <td>4360.215332</td>\n",
       "      <td>2302.835205</td>\n",
       "      <td>5054.364258</td>\n",
       "      <td>1829.826904</td>\n",
       "      <td>3210.021484</td>\n",
       "      <td>2502.509033</td>\n",
       "      <td>...</td>\n",
       "      <td>1.771815</td>\n",
       "      <td>14.466579</td>\n",
       "      <td>86.371120</td>\n",
       "      <td>0.074635</td>\n",
       "      <td>6.510337</td>\n",
       "      <td>5243.859649</td>\n",
       "      <td>15422.032531</td>\n",
       "      <td>579.817519</td>\n",
       "      <td>406.147341</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         music_id  chroma_0_mean  chroma_0_std  chroma_10_mean  chroma_10_std  \\\n",
       "count  320.000000     317.000000    317.000000      317.000000     317.000000   \n",
       "mean   159.500000     461.223799    727.558402      441.424764     664.515463   \n",
       "std     92.520268     302.890638    511.932682      286.127709     507.650090   \n",
       "min      0.000000      52.542076    108.190132       66.789970     129.553772   \n",
       "25%     79.750000     254.774170    388.372406      248.708359     350.873505   \n",
       "50%    159.500000     377.393036    571.490845      381.081177     534.109131   \n",
       "75%    239.250000     592.239685    910.419189      558.673584     803.034241   \n",
       "max    319.000000    1643.472900   3421.152100     2172.719482    4360.215332   \n",
       "\n",
       "       chroma_11_mean  chroma_11_std  chroma_1_mean  chroma_1_std  \\\n",
       "count      318.000000     320.000000     318.000000    319.000000   \n",
       "mean       420.808596     606.042905     417.116685    605.835885   \n",
       "std        284.887311     443.484753     269.444492    410.002545   \n",
       "min         64.062683     117.359634      50.826832     93.769897   \n",
       "25%        231.128601     344.294373     228.390095    353.000809   \n",
       "50%        340.970337     484.871140     354.934341    505.056274   \n",
       "75%        506.674622     752.747421     507.147308    702.858398   \n",
       "max       2302.835205    5054.364258    1829.826904   3210.021484   \n",
       "\n",
       "       chroma_2_mean  ...  mfcc_9_std  onset_rate  spectral_centroid_mean  \\\n",
       "count     316.000000  ...  317.000000  319.000000              318.000000   \n",
       "mean      469.942682  ...    0.629552    4.917406               28.050904   \n",
       "std       319.000592  ...    0.170709    2.537782               16.103779   \n",
       "min        50.655052  ...    0.405036    0.366504                1.656318   \n",
       "25%       258.015579  ...    0.515947    3.048645               16.354873   \n",
       "50%       403.037384  ...    0.583850    4.731231               24.205491   \n",
       "75%       568.195679  ...    0.683956    6.615188               37.958948   \n",
       "max      2502.509033  ...    1.771815   14.466579               86.371120   \n",
       "\n",
       "       spectral_decrease_mean  spectral_flux_mean  spectral_rolloff_mean  \\\n",
       "count              316.000000          316.000000             320.000000   \n",
       "mean                -0.155241            1.737679            1180.002741   \n",
       "std                  0.185176            1.063592             711.314460   \n",
       "min                 -0.650820            0.351351              21.491228   \n",
       "25%                 -0.287891            0.958037             687.719298   \n",
       "50%                 -0.086321            1.461911            1020.833333   \n",
       "75%                  0.002296            2.144044            1552.741228   \n",
       "max                  0.074635            6.510337            5243.859649   \n",
       "\n",
       "       spectral_spread_mean    zcr_mean     zcr_std    category  \n",
       "count            316.000000  316.000000  317.000000  320.000000  \n",
       "mean            1942.502831  192.060511  115.472340    1.500000  \n",
       "std             1984.500644  107.853027   53.495612    1.119785  \n",
       "min               41.709451   35.199924   32.996641    0.000000  \n",
       "25%              626.473435  114.992507   78.780289    0.750000  \n",
       "50%             1274.624056  167.636659  104.338107    1.500000  \n",
       "75%             2634.940367  240.335595  142.303996    2.250000  \n",
       "max            15422.032531  579.817519  406.147341    3.000000  \n",
       "\n",
       "[8 rows x 63 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()\n",
    "# Nous n'avons pas de valeur binaire ni de texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adverse-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous enlevons music_id de train et test car il n'est pas pertinent et nous gardons le résultat des catégories de train dans y\n",
    "df_train.drop(['music_id'], axis=1, inplace=True)\n",
    "df_test.drop(['music_id'], axis=1, inplace=True)\n",
    "y = df_train.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "egyptian-wells",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "arabic-release",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.countplot(x=\"category\", data=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sized-carolina",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chroma_0_mean            3\n",
       "chroma_0_std             3\n",
       "chroma_10_mean           3\n",
       "chroma_10_std            3\n",
       "chroma_11_mean           2\n",
       "                        ..\n",
       "spectral_rolloff_mean    0\n",
       "spectral_spread_mean     4\n",
       "zcr_mean                 4\n",
       "zcr_std                  3\n",
       "category                 0\n",
       "Length: 62, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "flexible-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nous remplacçons les valeurs NA via le KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "df_train= pd.DataFrame(imputer.fit_transform(df_train), columns=df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "coral-tours",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verification\n",
    "df_train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "alleged-aviation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chroma_0_mean</th>\n",
       "      <th>chroma_0_std</th>\n",
       "      <th>chroma_10_mean</th>\n",
       "      <th>chroma_10_std</th>\n",
       "      <th>chroma_11_mean</th>\n",
       "      <th>chroma_11_std</th>\n",
       "      <th>chroma_1_mean</th>\n",
       "      <th>chroma_1_std</th>\n",
       "      <th>chroma_2_mean</th>\n",
       "      <th>chroma_2_std</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_9_std</th>\n",
       "      <th>onset_rate</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_decrease_mean</th>\n",
       "      <th>spectral_flux_mean</th>\n",
       "      <th>spectral_rolloff_mean</th>\n",
       "      <th>spectral_spread_mean</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>zcr_std</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>866.507629</td>\n",
       "      <td>1585.437134</td>\n",
       "      <td>415.300842</td>\n",
       "      <td>710.790771</td>\n",
       "      <td>683.865845</td>\n",
       "      <td>1011.552856</td>\n",
       "      <td>473.484100</td>\n",
       "      <td>744.247925</td>\n",
       "      <td>304.914825</td>\n",
       "      <td>363.313141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647313</td>\n",
       "      <td>3.631719</td>\n",
       "      <td>27.621587</td>\n",
       "      <td>-0.186330</td>\n",
       "      <td>1.962404</td>\n",
       "      <td>1525.877193</td>\n",
       "      <td>1579.021838</td>\n",
       "      <td>190.907164</td>\n",
       "      <td>149.482276</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>832.956909</td>\n",
       "      <td>2140.568115</td>\n",
       "      <td>287.584564</td>\n",
       "      <td>281.795380</td>\n",
       "      <td>405.467224</td>\n",
       "      <td>754.076904</td>\n",
       "      <td>1061.359863</td>\n",
       "      <td>2263.894531</td>\n",
       "      <td>2502.509033</td>\n",
       "      <td>6418.287109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575588</td>\n",
       "      <td>6.230564</td>\n",
       "      <td>38.780628</td>\n",
       "      <td>-0.013198</td>\n",
       "      <td>2.139456</td>\n",
       "      <td>1740.789474</td>\n",
       "      <td>1941.791036</td>\n",
       "      <td>257.913214</td>\n",
       "      <td>171.257592</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>331.544586</td>\n",
       "      <td>553.657532</td>\n",
       "      <td>260.467499</td>\n",
       "      <td>327.618225</td>\n",
       "      <td>283.580139</td>\n",
       "      <td>312.385986</td>\n",
       "      <td>204.369690</td>\n",
       "      <td>225.922531</td>\n",
       "      <td>286.470215</td>\n",
       "      <td>396.768219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.837297</td>\n",
       "      <td>4.264771</td>\n",
       "      <td>86.371120</td>\n",
       "      <td>-0.155013</td>\n",
       "      <td>1.336048</td>\n",
       "      <td>5243.859649</td>\n",
       "      <td>15422.032531</td>\n",
       "      <td>508.122337</td>\n",
       "      <td>296.141124</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>454.521851</td>\n",
       "      <td>1170.188110</td>\n",
       "      <td>601.021790</td>\n",
       "      <td>1035.021240</td>\n",
       "      <td>721.523865</td>\n",
       "      <td>1861.131836</td>\n",
       "      <td>350.991791</td>\n",
       "      <td>495.942383</td>\n",
       "      <td>432.551971</td>\n",
       "      <td>563.184021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702976</td>\n",
       "      <td>4.064860</td>\n",
       "      <td>16.844325</td>\n",
       "      <td>-0.287745</td>\n",
       "      <td>2.207420</td>\n",
       "      <td>988.596491</td>\n",
       "      <td>999.051613</td>\n",
       "      <td>144.638374</td>\n",
       "      <td>142.303996</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.331635</td>\n",
       "      <td>245.818512</td>\n",
       "      <td>388.924744</td>\n",
       "      <td>917.082581</td>\n",
       "      <td>186.856262</td>\n",
       "      <td>192.765305</td>\n",
       "      <td>212.240402</td>\n",
       "      <td>370.108063</td>\n",
       "      <td>170.875610</td>\n",
       "      <td>225.814850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.487534</td>\n",
       "      <td>4.164816</td>\n",
       "      <td>5.764473</td>\n",
       "      <td>-0.626706</td>\n",
       "      <td>1.263404</td>\n",
       "      <td>21.491228</td>\n",
       "      <td>735.051431</td>\n",
       "      <td>181.818928</td>\n",
       "      <td>106.604597</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   chroma_0_mean  chroma_0_std  chroma_10_mean  chroma_10_std  chroma_11_mean  \\\n",
       "0     866.507629   1585.437134      415.300842     710.790771      683.865845   \n",
       "1     832.956909   2140.568115      287.584564     281.795380      405.467224   \n",
       "2     331.544586    553.657532      260.467499     327.618225      283.580139   \n",
       "3     454.521851   1170.188110      601.021790    1035.021240      721.523865   \n",
       "4     180.331635    245.818512      388.924744     917.082581      186.856262   \n",
       "\n",
       "   chroma_11_std  chroma_1_mean  chroma_1_std  chroma_2_mean  chroma_2_std  \\\n",
       "0    1011.552856     473.484100    744.247925     304.914825    363.313141   \n",
       "1     754.076904    1061.359863   2263.894531    2502.509033   6418.287109   \n",
       "2     312.385986     204.369690    225.922531     286.470215    396.768219   \n",
       "3    1861.131836     350.991791    495.942383     432.551971    563.184021   \n",
       "4     192.765305     212.240402    370.108063     170.875610    225.814850   \n",
       "\n",
       "   ...  mfcc_9_std  onset_rate  spectral_centroid_mean  \\\n",
       "0  ...    0.647313    3.631719               27.621587   \n",
       "1  ...    0.575588    6.230564               38.780628   \n",
       "2  ...    0.837297    4.264771               86.371120   \n",
       "3  ...    0.702976    4.064860               16.844325   \n",
       "4  ...    0.487534    4.164816                5.764473   \n",
       "\n",
       "   spectral_decrease_mean  spectral_flux_mean  spectral_rolloff_mean  \\\n",
       "0               -0.186330            1.962404            1525.877193   \n",
       "1               -0.013198            2.139456            1740.789474   \n",
       "2               -0.155013            1.336048            5243.859649   \n",
       "3               -0.287745            2.207420             988.596491   \n",
       "4               -0.626706            1.263404              21.491228   \n",
       "\n",
       "   spectral_spread_mean    zcr_mean     zcr_std  category  \n",
       "0           1579.021838  190.907164  149.482276       1.0  \n",
       "1           1941.791036  257.913214  171.257592       3.0  \n",
       "2          15422.032531  508.122337  296.141124       3.0  \n",
       "3            999.051613  144.638374  142.303996       1.0  \n",
       "4            735.051431  181.818928  106.604597       1.0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "configured-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On drop category\n",
    "df_train = df_train.drop(['category'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "early-tattoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On split les données 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepting-binary",
   "metadata": {},
   "source": [
    "## Voici ci-dessous la liste des modèles que j'ai essayé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "white-hampshire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Classifier accuracy :  0.75\n",
      "KNeighborsClassifier accuracy :  0.515625\n",
      "RandomForestClassifier accuracy :  0.65625\n",
      "GradientBoostingClassifier accuracy :  0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\louis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\louis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\louis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\louis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression accuracy :  0.578125\n",
      "LinearSVC accuracy :  0.546875\n",
      "SVC accuracy :  0.484375\n",
      "SVC accuracy :  0.609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\louis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier accuracy :  0.765625\n"
     ]
    }
   ],
   "source": [
    "lgb = LGBMClassifier(random_state=40,n_estimators=100,objective ='multiclass',num_leaves=31,num_class=3)\n",
    "lgb.fit(X_train, y_train)\n",
    "u=lgb.predict(X_test)\n",
    "\n",
    "print(\"LGBM Classifier accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train)\n",
    "u=neigh.predict(X_test)\n",
    "print(\"KNeighborsClassifier accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "u=clf.predict(X_test)\n",
    "print(\"RandomForestClassifier accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "u=clf.predict(X_test)\n",
    "print(\"GradientBoostingClassifier accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "LR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr')\n",
    "LR.fit(X_train, y_train)\n",
    "u=LR.predict(X_test)\n",
    "print(\"LogisticRegression accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "SVM = svm.LinearSVC()\n",
    "SVM.fit(X_train, y_train)\n",
    "u=SVM.predict(X_test)\n",
    "print(\"LinearSVC accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "SVM = svm.SVC()\n",
    "SVM.fit(X_train, y_train)\n",
    "u=SVM.predict(X_test)\n",
    "print(\"SVC accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "u=gnb.predict(X_test)\n",
    "print(\"SVC accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "u=clf.predict(X_test)\n",
    "print(\"RandomForestClassifier accuracy : \" , accuracy_score(u, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-guide",
   "metadata": {},
   "source": [
    "## SCALING DES DATA : j'ai voulu appliquer un scalling sur chaque modèle pour voir quel scalling était le plus efficace et ensuite selectionner le meilleur score de tous les essais ( oui ça pique les yeux désolé!)\n",
    "###  STANDARD SCALER :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "complex-reflection",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "related-tucson",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "personal-frederick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Classifier accuracy :  0.71875\n",
      "KNeighborsClassifier accuracy :  0.6875\n",
      "RandomForestClassifier accuracy :  0.65625\n",
      "GradientBoostingClassifier accuracy :  0.75\n",
      "LogisticRegression accuracy :  0.765625\n",
      "LinearSVC accuracy :  0.734375\n",
      "SVC accuracy :  0.78125\n",
      "Gnb accuracy :  0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\louis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier accuracy :  0.765625\n"
     ]
    }
   ],
   "source": [
    "lgb = LGBMClassifier(random_state=40,n_estimators=100,objective ='multiclass',num_leaves=31,num_class=3)\n",
    "lgb.fit(X_train, y_train)\n",
    "u=lgb.predict(X_test)\n",
    "\n",
    "print(\"LGBM Classifier accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train)\n",
    "u=neigh.predict(X_test)\n",
    "print(\"KNeighborsClassifier accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "u=clf.predict(X_test)\n",
    "print(\"RandomForestClassifier accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "u=clf.predict(X_test)\n",
    "print(\"GradientBoostingClassifier accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "LR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr')\n",
    "LR.fit(X_train, y_train)\n",
    "u=LR.predict(X_test)\n",
    "print(\"LogisticRegression accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "SVM = svm.LinearSVC()\n",
    "SVM.fit(X_train, y_train)\n",
    "u=SVM.predict(X_test)\n",
    "print(\"LinearSVC accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "SVM = svm.SVC()\n",
    "SVM.fit(X_train, y_train)\n",
    "u=SVM.predict(X_test)\n",
    "print(\"SVC accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "u=gnb.predict(X_test)\n",
    "print(\"Gnb accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "u=clf.predict(X_test)\n",
    "print(\"RandomForestClassifier accuracy : \" , accuracy_score(u, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-mailman",
   "metadata": {},
   "source": [
    "### MINMAXSCALER :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "resistant-finish",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "standing-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "#######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "specific-struggle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Classifier accuracy :  0.75\n",
      "KNeighborsClassifier accuracy :  0.703125\n",
      "RandomForestClassifier accuracy :  0.65625\n",
      "GradientBoostingClassifier accuracy :  0.75\n",
      "LogisticRegression accuracy :  0.765625\n",
      "LinearSVC accuracy :  0.796875\n",
      "SVC accuracy :  0.75\n",
      "Gnb accuracy :  0.625\n",
      "RandomForestClassifier accuracy :  0.765625\n"
     ]
    }
   ],
   "source": [
    "lgb = LGBMClassifier(random_state=40,n_estimators=100,objective ='multiclass',num_leaves=31,num_class=3)\n",
    "lgb.fit(X_train, y_train)\n",
    "u=lgb.predict(X_test)\n",
    "\n",
    "print(\"LGBM Classifier accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train)\n",
    "u=neigh.predict(X_test)\n",
    "print(\"KNeighborsClassifier accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "u=clf.predict(X_test)\n",
    "print(\"RandomForestClassifier accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "u=clf.predict(X_test)\n",
    "print(\"GradientBoostingClassifier accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "LR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr')\n",
    "LR.fit(X_train, y_train)\n",
    "u=LR.predict(X_test)\n",
    "print(\"LogisticRegression accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "SVM = svm.LinearSVC()\n",
    "SVM.fit(X_train, y_train)\n",
    "u=SVM.predict(X_test)\n",
    "print(\"LinearSVC accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "SVM = svm.SVC()\n",
    "SVM.fit(X_train, y_train)\n",
    "u=SVM.predict(X_test)\n",
    "print(\"SVC accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "u=gnb.predict(X_test)\n",
    "print(\"Gnb accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "u=clf.predict(X_test)\n",
    "print(\"RandomForestClassifier accuracy : \" , accuracy_score(u, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-intent",
   "metadata": {},
   "source": [
    "### RobustScaler :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "residential-robertson",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sticky-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "artificial-brave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Classifier accuracy :  0.734375\n",
      "KNeighborsClassifier accuracy :  0.6875\n",
      "RandomForestClassifier accuracy :  0.65625\n",
      "GradientBoostingClassifier accuracy :  0.75\n",
      "LogisticRegression accuracy :  0.765625\n",
      "LinearSVC accuracy :  0.703125\n",
      "Gnb accuracy :  0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\louis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier accuracy :  0.765625\n"
     ]
    }
   ],
   "source": [
    "lgb = LGBMClassifier(random_state=40,n_estimators=100,objective ='multiclass',num_leaves=31,num_class=3)\n",
    "lgb.fit(X_train, y_train)\n",
    "u=lgb.predict(X_test)\n",
    "\n",
    "print(\"LGBM Classifier accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train)\n",
    "u=neigh.predict(X_test)\n",
    "print(\"KNeighborsClassifier accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "u=clf.predict(X_test)\n",
    "print(\"RandomForestClassifier accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "u=clf.predict(X_test)\n",
    "print(\"GradientBoostingClassifier accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "LR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr')\n",
    "LR.fit(X_train, y_train)\n",
    "u=LR.predict(X_test)\n",
    "print(\"LogisticRegression accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "SVM = svm.LinearSVC()\n",
    "SVM.fit(X_train, y_train)\n",
    "u=SVM.predict(X_test)\n",
    "print(\"LinearSVC accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "u=gnb.predict(X_test)\n",
    "print(\"Gnb accuracy : \" , accuracy_score(u, y_test))\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "u=clf.predict(X_test)\n",
    "print(\"RandomForestClassifier accuracy : \" , accuracy_score(u, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-cabinet",
   "metadata": {},
   "source": [
    "## Les résultats sont sensiblement meilleurs avec le scalling MinMaxScaler. Pour la suite je vais travailler sur le meilleur résultat : le modèl LinearSVC\n",
    "\n",
    "### Pour améliorer ces données je vais voir si il y a des outliers, (effectivement cette étape de preprocessing aurait dû avoir lieu avant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "palestinian-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_train\n",
    "y = y.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "comprehensive-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suprresion des outliers en dessous du first et au dessus du third quartile\n",
    "def outlier_function(df_train, col_name):\n",
    "    first_quartile = np.percentile(np.array(df_train[col_name].tolist()), 25)\n",
    "    third_quartile = np.percentile(np.array(df_train[col_name].tolist()), 75)\n",
    "    IQR = third_quartile - first_quartile\n",
    "    \n",
    "    upper_limit = third_quartile+(3*IQR)\n",
    "    lower_limit = first_quartile-(3*IQR)\n",
    "    outlier_count = 0\n",
    "    \n",
    "    valeur = []\n",
    "    for value in df_train[col_name].tolist():\n",
    "        if (value < lower_limit) | (value > upper_limit):\n",
    "            outlier_count +=1\n",
    "            valeur.append(value)\n",
    "    return lower_limit, upper_limit, outlier_count, valeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "persistent-upset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 3 outliers dans chroma_0_mean\n",
      "Il y a 4 outliers dans chroma_0_std\n",
      "Il y a 2 outliers dans chroma_10_mean\n",
      "Il y a 7 outliers dans chroma_10_std\n",
      "Il y a 4 outliers dans chroma_11_mean\n",
      "Il y a 4 outliers dans chroma_11_std\n",
      "Il y a 3 outliers dans chroma_1_mean\n",
      "Il y a 5 outliers dans chroma_1_std\n",
      "Il y a 5 outliers dans chroma_2_mean\n",
      "Il y a 5 outliers dans chroma_2_std\n",
      "Il y a 4 outliers dans chroma_3_mean\n",
      "Il y a 9 outliers dans chroma_3_std\n",
      "Il y a 2 outliers dans chroma_4_mean\n",
      "Il y a 8 outliers dans chroma_4_std\n",
      "Il y a 3 outliers dans chroma_5_mean\n",
      "Il y a 7 outliers dans chroma_5_std\n",
      "Il y a 2 outliers dans chroma_6_mean\n",
      "Il y a 4 outliers dans chroma_6_std\n",
      "Il y a 1 outliers dans chroma_7_mean\n",
      "Il y a 7 outliers dans chroma_7_std\n",
      "Il y a 5 outliers dans chroma_8_mean\n",
      "Il y a 3 outliers dans chroma_8_std\n",
      "Il y a 2 outliers dans chroma_9_mean\n",
      "Il y a 7 outliers dans chroma_9_std\n",
      "Il y a 2 outliers dans chroma_centroid_mean\n",
      "Il y a 1 outliers dans chroma_flux_mean\n",
      "Il y a 3 outliers dans chroma_max\n",
      "Il y a 10 outliers dans chroma_min\n",
      "Il y a 1 outliers dans chroma_spread_mean\n",
      "Il y a 1 outliers dans mfcc_11_std\n",
      "Il y a 3 outliers dans mfcc_12_std\n",
      "Il y a 1 outliers dans mfcc_13_mean\n",
      "Il y a 1 outliers dans mfcc_13_std\n",
      "Il y a 1 outliers dans mfcc_2_mean\n",
      "Il y a 2 outliers dans mfcc_5_std\n",
      "Il y a 1 outliers dans mfcc_6_mean\n",
      "Il y a 2 outliers dans mfcc_6_std\n",
      "Il y a 2 outliers dans mfcc_7_std\n",
      "Il y a 2 outliers dans mfcc_8_std\n",
      "Il y a 1 outliers dans mfcc_9_mean\n",
      "Il y a 3 outliers dans mfcc_9_std\n",
      "Il y a 3 outliers dans spectral_flux_mean\n",
      "Il y a 1 outliers dans spectral_rolloff_mean\n",
      "Il y a 4 outliers dans spectral_spread_mean\n",
      "Il y a 1 outliers dans zcr_std\n"
     ]
    }
   ],
   "source": [
    "for i in x.columns:\n",
    "    if outlier_function(x, i)[2] > 0:\n",
    "        print(\"Il y a {} outliers dans {}\".format(outlier_function(x, i)[2], i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "contained-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des outliers\n",
    "listeindexdrop = []\n",
    "for i in x.columns:\n",
    "    if outlier_function(x, i)[2] > 0:\n",
    "        #print(\"Il y a {} outliers dans {}\".format(outlier_function(x, i)[2], i))\n",
    "        liste_outlier= outlier_function(x, i)[3]\n",
    "        for j in x[i].values:\n",
    "            if j in liste_outlier:\n",
    "                listeindexdrop.append(x.loc[x[i]==j].index[0])\n",
    "len(listeindexdrop)#152\n",
    "listeindexdrop = list(set(listeindexdrop))\n",
    "len(listeindexdrop)#64\n",
    "listeindexdrop.sort()\n",
    "id=0\n",
    "for i in listeindexdrop:\n",
    "    x.drop(x.index[i-id], inplace=True)\n",
    "    y.drop(y.index[i-id], inplace=True)\n",
    "    id = id+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "loving-journalist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resplit oui, c'est pas top de le refaire 20 fois dans le même notebook\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "demonstrated-oxygen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "macro-poison",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC accuracy :  0.9038461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\louis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "SVM = svm.LinearSVC()\n",
    "SVM.fit(X_train, y_train)\n",
    "u=SVM.predict(X_test)\n",
    "print(\"LinearSVC accuracy : \" , accuracy_score(u, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "superb-electric",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0  0]\n",
      " [ 0 11  1  2]\n",
      " [ 0  1 17  1]\n",
      " [ 0  0  0  6]]\n"
     ]
    }
   ],
   "source": [
    "# Matrice de confusion\n",
    "cf_matrix=confusion_matrix(u,y_test)\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "tracked-female",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(figsize=(16, 12))\n",
    "sns.heatmap(cf_matrix,annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-iceland",
   "metadata": {},
   "source": [
    "### Essayons de faire une pca pour améliorer nos performances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "actual-psychiatry",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pca=x.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "natural-corporation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chroma_0_mean</th>\n",
       "      <th>chroma_0_std</th>\n",
       "      <th>chroma_10_mean</th>\n",
       "      <th>chroma_10_std</th>\n",
       "      <th>chroma_11_mean</th>\n",
       "      <th>chroma_11_std</th>\n",
       "      <th>chroma_1_mean</th>\n",
       "      <th>chroma_1_std</th>\n",
       "      <th>chroma_2_mean</th>\n",
       "      <th>chroma_2_std</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_9_mean</th>\n",
       "      <th>mfcc_9_std</th>\n",
       "      <th>onset_rate</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_decrease_mean</th>\n",
       "      <th>spectral_flux_mean</th>\n",
       "      <th>spectral_rolloff_mean</th>\n",
       "      <th>spectral_spread_mean</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>zcr_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>454.521851</td>\n",
       "      <td>1170.188110</td>\n",
       "      <td>601.021790</td>\n",
       "      <td>1035.021240</td>\n",
       "      <td>721.523865</td>\n",
       "      <td>1861.131836</td>\n",
       "      <td>350.991791</td>\n",
       "      <td>495.942383</td>\n",
       "      <td>432.551971</td>\n",
       "      <td>563.184021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257047</td>\n",
       "      <td>0.702976</td>\n",
       "      <td>4.064860</td>\n",
       "      <td>16.844325</td>\n",
       "      <td>-0.287745</td>\n",
       "      <td>2.207420</td>\n",
       "      <td>988.596491</td>\n",
       "      <td>999.051613</td>\n",
       "      <td>144.638374</td>\n",
       "      <td>142.303996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>623.636475</td>\n",
       "      <td>1185.141235</td>\n",
       "      <td>356.477631</td>\n",
       "      <td>438.765228</td>\n",
       "      <td>436.773651</td>\n",
       "      <td>584.193237</td>\n",
       "      <td>519.140076</td>\n",
       "      <td>607.874695</td>\n",
       "      <td>886.185425</td>\n",
       "      <td>1343.947998</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179700</td>\n",
       "      <td>0.817544</td>\n",
       "      <td>4.731231</td>\n",
       "      <td>33.695191</td>\n",
       "      <td>0.006474</td>\n",
       "      <td>1.644274</td>\n",
       "      <td>1310.964912</td>\n",
       "      <td>753.759663</td>\n",
       "      <td>179.852651</td>\n",
       "      <td>88.762234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>202.341812</td>\n",
       "      <td>289.642334</td>\n",
       "      <td>154.299088</td>\n",
       "      <td>197.096191</td>\n",
       "      <td>175.142578</td>\n",
       "      <td>296.743988</td>\n",
       "      <td>127.823761</td>\n",
       "      <td>150.595825</td>\n",
       "      <td>95.901791</td>\n",
       "      <td>348.950867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113059</td>\n",
       "      <td>0.497695</td>\n",
       "      <td>3.298534</td>\n",
       "      <td>7.437169</td>\n",
       "      <td>-0.525607</td>\n",
       "      <td>0.579028</td>\n",
       "      <td>214.912281</td>\n",
       "      <td>544.688458</td>\n",
       "      <td>109.475711</td>\n",
       "      <td>37.981397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>256.068146</td>\n",
       "      <td>419.610474</td>\n",
       "      <td>154.441422</td>\n",
       "      <td>241.447266</td>\n",
       "      <td>192.383408</td>\n",
       "      <td>342.736816</td>\n",
       "      <td>191.470200</td>\n",
       "      <td>264.553986</td>\n",
       "      <td>184.699219</td>\n",
       "      <td>299.975769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042138</td>\n",
       "      <td>0.486629</td>\n",
       "      <td>4.233308</td>\n",
       "      <td>10.201029</td>\n",
       "      <td>-0.470241</td>\n",
       "      <td>1.461510</td>\n",
       "      <td>537.280702</td>\n",
       "      <td>1069.792914</td>\n",
       "      <td>135.532742</td>\n",
       "      <td>81.179168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>681.930420</td>\n",
       "      <td>1243.771484</td>\n",
       "      <td>637.555603</td>\n",
       "      <td>874.287659</td>\n",
       "      <td>621.384094</td>\n",
       "      <td>916.178772</td>\n",
       "      <td>472.486176</td>\n",
       "      <td>832.650085</td>\n",
       "      <td>394.936432</td>\n",
       "      <td>772.421143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273687</td>\n",
       "      <td>0.601287</td>\n",
       "      <td>5.264327</td>\n",
       "      <td>17.964051</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>1.918716</td>\n",
       "      <td>580.263158</td>\n",
       "      <td>358.190976</td>\n",
       "      <td>113.107438</td>\n",
       "      <td>68.767890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   chroma_0_mean  chroma_0_std  chroma_10_mean  chroma_10_std  chroma_11_mean  \\\n",
       "3     454.521851   1170.188110      601.021790    1035.021240      721.523865   \n",
       "5     623.636475   1185.141235      356.477631     438.765228      436.773651   \n",
       "6     202.341812    289.642334      154.299088     197.096191      175.142578   \n",
       "8     256.068146    419.610474      154.441422     241.447266      192.383408   \n",
       "9     681.930420   1243.771484      637.555603     874.287659      621.384094   \n",
       "\n",
       "   chroma_11_std  chroma_1_mean  chroma_1_std  chroma_2_mean  chroma_2_std  \\\n",
       "3    1861.131836     350.991791    495.942383     432.551971    563.184021   \n",
       "5     584.193237     519.140076    607.874695     886.185425   1343.947998   \n",
       "6     296.743988     127.823761    150.595825      95.901791    348.950867   \n",
       "8     342.736816     191.470200    264.553986     184.699219    299.975769   \n",
       "9     916.178772     472.486176    832.650085     394.936432    772.421143   \n",
       "\n",
       "   ...  mfcc_9_mean  mfcc_9_std  onset_rate  spectral_centroid_mean  \\\n",
       "3  ...     0.257047    0.702976    4.064860               16.844325   \n",
       "5  ...    -0.179700    0.817544    4.731231               33.695191   \n",
       "6  ...     0.113059    0.497695    3.298534                7.437169   \n",
       "8  ...     0.042138    0.486629    4.233308               10.201029   \n",
       "9  ...     0.273687    0.601287    5.264327               17.964051   \n",
       "\n",
       "   spectral_decrease_mean  spectral_flux_mean  spectral_rolloff_mean  \\\n",
       "3               -0.287745            2.207420             988.596491   \n",
       "5                0.006474            1.644274            1310.964912   \n",
       "6               -0.525607            0.579028             214.912281   \n",
       "8               -0.470241            1.461510             537.280702   \n",
       "9                0.002828            1.918716             580.263158   \n",
       "\n",
       "   spectral_spread_mean    zcr_mean     zcr_std  \n",
       "3            999.051613  144.638374  142.303996  \n",
       "5            753.759663  179.852651   88.762234  \n",
       "6            544.688458  109.475711   37.981397  \n",
       "8           1069.792914  135.532742   81.179168  \n",
       "9            358.190976  113.107438   68.767890  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "modular-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=40)   # j'ai essayé jusqu'à 60 et je n'obtients jamais de meilleure performance \n",
    "principle=pca.fit_transform(x_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "handmade-municipality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14064.259603</td>\n",
       "      <td>514.266145</td>\n",
       "      <td>-325.803994</td>\n",
       "      <td>-63.376128</td>\n",
       "      <td>-357.821408</td>\n",
       "      <td>-210.141331</td>\n",
       "      <td>-312.438893</td>\n",
       "      <td>88.696606</td>\n",
       "      <td>-445.246476</td>\n",
       "      <td>580.525734</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.030434</td>\n",
       "      <td>0.728399</td>\n",
       "      <td>-0.143421</td>\n",
       "      <td>-0.793554</td>\n",
       "      <td>-0.378046</td>\n",
       "      <td>-0.464588</td>\n",
       "      <td>0.119469</td>\n",
       "      <td>0.180675</td>\n",
       "      <td>-0.494249</td>\n",
       "      <td>-0.288920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25454.047117</td>\n",
       "      <td>1190.543640</td>\n",
       "      <td>-1835.159398</td>\n",
       "      <td>-23.378046</td>\n",
       "      <td>-336.144860</td>\n",
       "      <td>-229.225797</td>\n",
       "      <td>1195.095406</td>\n",
       "      <td>-418.199195</td>\n",
       "      <td>559.987933</td>\n",
       "      <td>-74.563497</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.122001</td>\n",
       "      <td>4.603978</td>\n",
       "      <td>1.389146</td>\n",
       "      <td>0.173329</td>\n",
       "      <td>0.460852</td>\n",
       "      <td>-0.164300</td>\n",
       "      <td>-0.155195</td>\n",
       "      <td>-0.020872</td>\n",
       "      <td>-0.291394</td>\n",
       "      <td>0.241224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3267.476507</td>\n",
       "      <td>-2216.915052</td>\n",
       "      <td>-686.693067</td>\n",
       "      <td>-365.978922</td>\n",
       "      <td>-231.475473</td>\n",
       "      <td>-152.139375</td>\n",
       "      <td>152.671564</td>\n",
       "      <td>-58.999651</td>\n",
       "      <td>43.352518</td>\n",
       "      <td>239.211782</td>\n",
       "      <td>...</td>\n",
       "      <td>2.536954</td>\n",
       "      <td>3.216567</td>\n",
       "      <td>0.319423</td>\n",
       "      <td>-1.031716</td>\n",
       "      <td>-0.138238</td>\n",
       "      <td>0.082606</td>\n",
       "      <td>0.216515</td>\n",
       "      <td>-0.325003</td>\n",
       "      <td>-0.333537</td>\n",
       "      <td>-0.038838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5814.810648</td>\n",
       "      <td>-1530.758594</td>\n",
       "      <td>288.514980</td>\n",
       "      <td>-81.920352</td>\n",
       "      <td>-290.085061</td>\n",
       "      <td>314.329992</td>\n",
       "      <td>-236.115633</td>\n",
       "      <td>-211.113309</td>\n",
       "      <td>200.956667</td>\n",
       "      <td>52.374637</td>\n",
       "      <td>...</td>\n",
       "      <td>4.208008</td>\n",
       "      <td>-4.651244</td>\n",
       "      <td>-0.702322</td>\n",
       "      <td>0.196303</td>\n",
       "      <td>-0.832384</td>\n",
       "      <td>0.396106</td>\n",
       "      <td>0.167777</td>\n",
       "      <td>0.292370</td>\n",
       "      <td>-0.085019</td>\n",
       "      <td>-0.273692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166.396060</td>\n",
       "      <td>-1195.082446</td>\n",
       "      <td>1549.819877</td>\n",
       "      <td>40.747060</td>\n",
       "      <td>-279.830633</td>\n",
       "      <td>-791.614020</td>\n",
       "      <td>-336.995378</td>\n",
       "      <td>221.072488</td>\n",
       "      <td>-191.009940</td>\n",
       "      <td>-19.531034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508889</td>\n",
       "      <td>-3.326716</td>\n",
       "      <td>-0.030346</td>\n",
       "      <td>0.520138</td>\n",
       "      <td>-0.458557</td>\n",
       "      <td>-0.533286</td>\n",
       "      <td>-0.053051</td>\n",
       "      <td>-0.116242</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.055960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0            1            2           3           4           5   \\\n",
       "0  14064.259603   514.266145  -325.803994  -63.376128 -357.821408 -210.141331   \n",
       "1  25454.047117  1190.543640 -1835.159398  -23.378046 -336.144860 -229.225797   \n",
       "2  -3267.476507 -2216.915052  -686.693067 -365.978922 -231.475473 -152.139375   \n",
       "3  -5814.810648 -1530.758594   288.514980  -81.920352 -290.085061  314.329992   \n",
       "4    166.396060 -1195.082446  1549.819877   40.747060 -279.830633 -791.614020   \n",
       "\n",
       "            6           7           8           9   ...        30        31  \\\n",
       "0  -312.438893   88.696606 -445.246476  580.525734  ... -1.030434  0.728399   \n",
       "1  1195.095406 -418.199195  559.987933  -74.563497  ... -8.122001  4.603978   \n",
       "2   152.671564  -58.999651   43.352518  239.211782  ...  2.536954  3.216567   \n",
       "3  -236.115633 -211.113309  200.956667   52.374637  ...  4.208008 -4.651244   \n",
       "4  -336.995378  221.072488 -191.009940  -19.531034  ...  0.508889 -3.326716   \n",
       "\n",
       "         32        33        34        35        36        37        38  \\\n",
       "0 -0.143421 -0.793554 -0.378046 -0.464588  0.119469  0.180675 -0.494249   \n",
       "1  1.389146  0.173329  0.460852 -0.164300 -0.155195 -0.020872 -0.291394   \n",
       "2  0.319423 -1.031716 -0.138238  0.082606  0.216515 -0.325003 -0.333537   \n",
       "3 -0.702322  0.196303 -0.832384  0.396106  0.167777  0.292370 -0.085019   \n",
       "4 -0.030346  0.520138 -0.458557 -0.533286 -0.053051 -0.116242  0.001515   \n",
       "\n",
       "         39  \n",
       "0 -0.288920  \n",
       "1  0.241224  \n",
       "2 -0.038838  \n",
       "3 -0.273692  \n",
       "4  0.055960  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pca=pd.DataFrame(data=principle)\n",
    "x_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "liable-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_pca, y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "known-shame",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC accuracy :  0.6923076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\louis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "c:\\users\\louis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "SVM = svm.LinearSVC()\n",
    "SVM.fit(X_train, y_train)\n",
    "u=SVM.predict(X_test)\n",
    "print(\"LinearSVC accuracy : \" , accuracy_score(u, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-essex",
   "metadata": {},
   "source": [
    "## La pca ne nous a pas aidé sur la performance du model, nous allons donc continuer à chercher comment améliorer ce score\n",
    "### Je vais chercher comment ameliorer les paramêtres de mon model\n",
    "D'après la documentation sklearn nous pouvons changer plusieurs paramètres :\n",
    "- Penalty : 'l1' ou 'l2'  l1 est utilisé si nos vectors sont sparse ce qui n'est pas le cas ici\n",
    "- loss : spécifie la fonction loss : hinge ou squared_hinge, nous avons un meilleur résultat avec squared_hinge\n",
    "- dual : booleen, False si nous avons + de données que de features, ce qui est le cas ici\n",
    "- tol : Tolérance pour les critères d'arret. A partir >0.1 nous n'arrivons pas à augmenter la performance \n",
    "- multi_class : 'ovr' ou 'crammer_singer', nous avons + de 2 classes donc nous choississons 'ovr'\n",
    "- fit_intercept booleen : Indique si il faut calculer l'intersection, ici rien n'améliore\n",
    "- random_state : inutile\n",
    "- max_iter : à partir de 15 nous avons notre performance maximale\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "looking-river",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cultural-garlic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "equivalent-teaching",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC accuracy :  0.9038461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\louis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "SVM = svm.LinearSVC(penalty='l2', loss='squared_hinge', dual=False, \n",
    "                    tol=0.1, multi_class='ovr', fit_intercept=False, max_iter=15, C=1)\n",
    "SVM.fit(X_train, y_train)\n",
    "u=SVM.predict(X_test)\n",
    "print(\"LinearSVC accuracy : \" , accuracy_score(u, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "green-uncle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ TRAINING ACCURACY -------\n",
      "0.9656862745098039\n",
      "------ TRAINING F-SCORE -------\n",
      "PRECISION SUR LA CATEGORIE 0 = 0.9791666666666666\n",
      "PRECISION SUR LA CATEGORIE 1 = 0.9565217391304347\n",
      "PRECISION SUR LA CATEGORIE 2 = 0.9642857142857143\n",
      "PRECISION SUR LA CATEGORIE 3 = 0.9647058823529412\n",
      "------ VALIDATION ACCURACY -------\n",
      "0.9038461538461539\n",
      "------ VALIDATION F-SCORE -------\n",
      "PRECISION SUR LA CATEGORIE 0 = 1.0\n",
      "PRECISION SUR LA CATEGORIE 1 = 0.8461538461538461\n",
      "PRECISION SUR LA CATEGORIE 2 = 0.918918918918919\n",
      "PRECISION SUR LA CATEGORIE 3 = 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\louis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(33.0, 0.5, 'Réel')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(svm.LinearSVC())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_predict = model.predict(X_train)\n",
    "y_test_predict = model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print('------ TRAINING ACCURACY -------')\n",
    "print(accuracy_score(y_train, y_train_predict))\n",
    "\n",
    "\n",
    "print('------ TRAINING F-SCORE -------')\n",
    "classes = f1_score(y_train, y_train_predict, average=None)\n",
    "\n",
    "for (cat, score) in enumerate(classes):\n",
    "    print('PRECISION SUR LA CATEGORIE ' + str(cat) + ' = ' + str(score))\n",
    "\n",
    "\n",
    "print('------ VALIDATION ACCURACY -------')\n",
    "print(accuracy_score(y_test, y_test_predict))\n",
    "\n",
    "print('------ VALIDATION F-SCORE -------')\n",
    "classes = f1_score(y_test, y_test_predict, average=None)\n",
    "\n",
    "for (cat, score) in enumerate(classes):\n",
    "    print('PRECISION SUR LA CATEGORIE ' + str(cat) + ' = ' + str(score))\n",
    "\n",
    "cm_val = confusion_matrix(y_test, y_test_predict)\n",
    "heatmap_val = sns.heatmap(cm_val, annot=True)\n",
    "\n",
    "heatmap_val.set_xlabel('Predit')\n",
    "heatmap_val.set_ylabel('Réel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-hungary",
   "metadata": {},
   "source": [
    "##  Nous cherchons une selection des features pour notre model LinearSvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "speaking-income",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled=x.copy() #on copie nos données scallées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "upper-bailey",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\louis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chroma_centroid_mean</th>\n",
       "      <th>chroma_spread_mean</th>\n",
       "      <th>mfcc_10_std</th>\n",
       "      <th>mfcc_11_std</th>\n",
       "      <th>mfcc_12_mean</th>\n",
       "      <th>mfcc_12_std</th>\n",
       "      <th>mfcc_13_mean</th>\n",
       "      <th>mfcc_13_std</th>\n",
       "      <th>mfcc_2_mean</th>\n",
       "      <th>mfcc_2_std</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_6_std</th>\n",
       "      <th>mfcc_7_mean</th>\n",
       "      <th>mfcc_7_std</th>\n",
       "      <th>mfcc_8_mean</th>\n",
       "      <th>mfcc_8_std</th>\n",
       "      <th>mfcc_9_mean</th>\n",
       "      <th>mfcc_9_std</th>\n",
       "      <th>onset_rate</th>\n",
       "      <th>spectral_decrease_mean</th>\n",
       "      <th>spectral_flux_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.748345</td>\n",
       "      <td>11.268784</td>\n",
       "      <td>0.500206</td>\n",
       "      <td>0.539651</td>\n",
       "      <td>-0.138668</td>\n",
       "      <td>0.613281</td>\n",
       "      <td>0.031876</td>\n",
       "      <td>0.533558</td>\n",
       "      <td>0.131419</td>\n",
       "      <td>1.178031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733236</td>\n",
       "      <td>0.962989</td>\n",
       "      <td>0.560574</td>\n",
       "      <td>-0.014520</td>\n",
       "      <td>0.685316</td>\n",
       "      <td>0.257047</td>\n",
       "      <td>0.702976</td>\n",
       "      <td>4.064860</td>\n",
       "      <td>-0.287745</td>\n",
       "      <td>2.207420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.233812</td>\n",
       "      <td>10.372887</td>\n",
       "      <td>0.635126</td>\n",
       "      <td>0.680836</td>\n",
       "      <td>-0.063558</td>\n",
       "      <td>0.610217</td>\n",
       "      <td>-0.178287</td>\n",
       "      <td>0.613811</td>\n",
       "      <td>-0.173151</td>\n",
       "      <td>0.765720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.606939</td>\n",
       "      <td>0.375948</td>\n",
       "      <td>0.578541</td>\n",
       "      <td>-0.406359</td>\n",
       "      <td>0.736854</td>\n",
       "      <td>-0.179700</td>\n",
       "      <td>0.817544</td>\n",
       "      <td>4.731231</td>\n",
       "      <td>0.006474</td>\n",
       "      <td>1.644274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.692751</td>\n",
       "      <td>11.302124</td>\n",
       "      <td>0.476492</td>\n",
       "      <td>0.542412</td>\n",
       "      <td>-0.006443</td>\n",
       "      <td>0.607704</td>\n",
       "      <td>0.041675</td>\n",
       "      <td>0.632535</td>\n",
       "      <td>-0.162674</td>\n",
       "      <td>0.926109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417751</td>\n",
       "      <td>0.550384</td>\n",
       "      <td>0.464843</td>\n",
       "      <td>0.105837</td>\n",
       "      <td>0.487410</td>\n",
       "      <td>0.113059</td>\n",
       "      <td>0.497695</td>\n",
       "      <td>3.298534</td>\n",
       "      <td>-0.525607</td>\n",
       "      <td>0.579028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.197120</td>\n",
       "      <td>8.904299</td>\n",
       "      <td>0.535092</td>\n",
       "      <td>0.502324</td>\n",
       "      <td>0.236872</td>\n",
       "      <td>0.541141</td>\n",
       "      <td>0.061972</td>\n",
       "      <td>0.563608</td>\n",
       "      <td>0.244944</td>\n",
       "      <td>1.115820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.629603</td>\n",
       "      <td>0.332233</td>\n",
       "      <td>0.533052</td>\n",
       "      <td>0.132123</td>\n",
       "      <td>0.616916</td>\n",
       "      <td>0.042138</td>\n",
       "      <td>0.486629</td>\n",
       "      <td>4.233308</td>\n",
       "      <td>-0.470241</td>\n",
       "      <td>1.461510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.841007</td>\n",
       "      <td>10.379212</td>\n",
       "      <td>0.515122</td>\n",
       "      <td>0.490599</td>\n",
       "      <td>-0.041908</td>\n",
       "      <td>0.464458</td>\n",
       "      <td>0.066722</td>\n",
       "      <td>0.481300</td>\n",
       "      <td>-0.018802</td>\n",
       "      <td>0.882304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.660254</td>\n",
       "      <td>0.565432</td>\n",
       "      <td>0.749337</td>\n",
       "      <td>-0.083488</td>\n",
       "      <td>0.590379</td>\n",
       "      <td>0.273687</td>\n",
       "      <td>0.601287</td>\n",
       "      <td>5.264327</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>1.918716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>5.929152</td>\n",
       "      <td>9.513753</td>\n",
       "      <td>0.748362</td>\n",
       "      <td>0.790134</td>\n",
       "      <td>0.025183</td>\n",
       "      <td>0.670908</td>\n",
       "      <td>-0.062463</td>\n",
       "      <td>0.679653</td>\n",
       "      <td>-0.160265</td>\n",
       "      <td>0.756185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.589475</td>\n",
       "      <td>0.138063</td>\n",
       "      <td>0.663172</td>\n",
       "      <td>0.285155</td>\n",
       "      <td>0.708033</td>\n",
       "      <td>-0.226337</td>\n",
       "      <td>0.682789</td>\n",
       "      <td>4.231453</td>\n",
       "      <td>-0.181232</td>\n",
       "      <td>0.868810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>5.821501</td>\n",
       "      <td>8.679995</td>\n",
       "      <td>0.761179</td>\n",
       "      <td>0.749808</td>\n",
       "      <td>0.105986</td>\n",
       "      <td>0.879557</td>\n",
       "      <td>-0.261431</td>\n",
       "      <td>0.644497</td>\n",
       "      <td>-0.306386</td>\n",
       "      <td>0.920233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.779780</td>\n",
       "      <td>0.275190</td>\n",
       "      <td>0.723163</td>\n",
       "      <td>-0.282397</td>\n",
       "      <td>0.642668</td>\n",
       "      <td>0.127569</td>\n",
       "      <td>0.676786</td>\n",
       "      <td>2.665482</td>\n",
       "      <td>-0.173625</td>\n",
       "      <td>0.970722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>6.184446</td>\n",
       "      <td>8.700215</td>\n",
       "      <td>0.573469</td>\n",
       "      <td>0.474020</td>\n",
       "      <td>0.289555</td>\n",
       "      <td>0.545385</td>\n",
       "      <td>0.080888</td>\n",
       "      <td>0.526374</td>\n",
       "      <td>0.254336</td>\n",
       "      <td>1.200981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.714500</td>\n",
       "      <td>0.433145</td>\n",
       "      <td>0.703136</td>\n",
       "      <td>0.402846</td>\n",
       "      <td>0.773200</td>\n",
       "      <td>0.056780</td>\n",
       "      <td>0.538871</td>\n",
       "      <td>3.031986</td>\n",
       "      <td>-0.255245</td>\n",
       "      <td>1.293797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>5.314267</td>\n",
       "      <td>10.165566</td>\n",
       "      <td>0.514722</td>\n",
       "      <td>0.450348</td>\n",
       "      <td>-0.091104</td>\n",
       "      <td>0.448779</td>\n",
       "      <td>-0.268272</td>\n",
       "      <td>0.539432</td>\n",
       "      <td>-0.128603</td>\n",
       "      <td>0.715080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.632480</td>\n",
       "      <td>0.287577</td>\n",
       "      <td>0.553505</td>\n",
       "      <td>0.074840</td>\n",
       "      <td>0.513010</td>\n",
       "      <td>0.094162</td>\n",
       "      <td>0.540750</td>\n",
       "      <td>7.696579</td>\n",
       "      <td>0.015666</td>\n",
       "      <td>1.431960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>5.658378</td>\n",
       "      <td>12.372905</td>\n",
       "      <td>0.420755</td>\n",
       "      <td>0.377322</td>\n",
       "      <td>0.065583</td>\n",
       "      <td>0.431700</td>\n",
       "      <td>0.038381</td>\n",
       "      <td>0.378824</td>\n",
       "      <td>0.099722</td>\n",
       "      <td>1.221142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527379</td>\n",
       "      <td>0.678488</td>\n",
       "      <td>0.475063</td>\n",
       "      <td>-0.087988</td>\n",
       "      <td>0.445508</td>\n",
       "      <td>0.176586</td>\n",
       "      <td>0.493347</td>\n",
       "      <td>8.533282</td>\n",
       "      <td>0.014588</td>\n",
       "      <td>3.890901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     chroma_centroid_mean  chroma_spread_mean  mfcc_10_std  mfcc_11_std  \\\n",
       "0                5.748345           11.268784     0.500206     0.539651   \n",
       "1                5.233812           10.372887     0.635126     0.680836   \n",
       "2                5.692751           11.302124     0.476492     0.542412   \n",
       "3                5.197120            8.904299     0.535092     0.502324   \n",
       "4                5.841007           10.379212     0.515122     0.490599   \n",
       "..                    ...                 ...          ...          ...   \n",
       "251              5.929152            9.513753     0.748362     0.790134   \n",
       "252              5.821501            8.679995     0.761179     0.749808   \n",
       "253              6.184446            8.700215     0.573469     0.474020   \n",
       "254              5.314267           10.165566     0.514722     0.450348   \n",
       "255              5.658378           12.372905     0.420755     0.377322   \n",
       "\n",
       "     mfcc_12_mean  mfcc_12_std  mfcc_13_mean  mfcc_13_std  mfcc_2_mean  \\\n",
       "0       -0.138668     0.613281      0.031876     0.533558     0.131419   \n",
       "1       -0.063558     0.610217     -0.178287     0.613811    -0.173151   \n",
       "2       -0.006443     0.607704      0.041675     0.632535    -0.162674   \n",
       "3        0.236872     0.541141      0.061972     0.563608     0.244944   \n",
       "4       -0.041908     0.464458      0.066722     0.481300    -0.018802   \n",
       "..            ...          ...           ...          ...          ...   \n",
       "251      0.025183     0.670908     -0.062463     0.679653    -0.160265   \n",
       "252      0.105986     0.879557     -0.261431     0.644497    -0.306386   \n",
       "253      0.289555     0.545385      0.080888     0.526374     0.254336   \n",
       "254     -0.091104     0.448779     -0.268272     0.539432    -0.128603   \n",
       "255      0.065583     0.431700      0.038381     0.378824     0.099722   \n",
       "\n",
       "     mfcc_2_std  ...  mfcc_6_std  mfcc_7_mean  mfcc_7_std  mfcc_8_mean  \\\n",
       "0      1.178031  ...    0.733236     0.962989    0.560574    -0.014520   \n",
       "1      0.765720  ...    0.606939     0.375948    0.578541    -0.406359   \n",
       "2      0.926109  ...    0.417751     0.550384    0.464843     0.105837   \n",
       "3      1.115820  ...    0.629603     0.332233    0.533052     0.132123   \n",
       "4      0.882304  ...    0.660254     0.565432    0.749337    -0.083488   \n",
       "..          ...  ...         ...          ...         ...          ...   \n",
       "251    0.756185  ...    0.589475     0.138063    0.663172     0.285155   \n",
       "252    0.920233  ...    0.779780     0.275190    0.723163    -0.282397   \n",
       "253    1.200981  ...    0.714500     0.433145    0.703136     0.402846   \n",
       "254    0.715080  ...    0.632480     0.287577    0.553505     0.074840   \n",
       "255    1.221142  ...    0.527379     0.678488    0.475063    -0.087988   \n",
       "\n",
       "     mfcc_8_std  mfcc_9_mean  mfcc_9_std  onset_rate  spectral_decrease_mean  \\\n",
       "0      0.685316     0.257047    0.702976    4.064860               -0.287745   \n",
       "1      0.736854    -0.179700    0.817544    4.731231                0.006474   \n",
       "2      0.487410     0.113059    0.497695    3.298534               -0.525607   \n",
       "3      0.616916     0.042138    0.486629    4.233308               -0.470241   \n",
       "4      0.590379     0.273687    0.601287    5.264327                0.002828   \n",
       "..          ...          ...         ...         ...                     ...   \n",
       "251    0.708033    -0.226337    0.682789    4.231453               -0.181232   \n",
       "252    0.642668     0.127569    0.676786    2.665482               -0.173625   \n",
       "253    0.773200     0.056780    0.538871    3.031986               -0.255245   \n",
       "254    0.513010     0.094162    0.540750    7.696579                0.015666   \n",
       "255    0.445508     0.176586    0.493347    8.533282                0.014588   \n",
       "\n",
       "     spectral_flux_mean  \n",
       "0              2.207420  \n",
       "1              1.644274  \n",
       "2              0.579028  \n",
       "3              1.461510  \n",
       "4              1.918716  \n",
       "..                  ...  \n",
       "251            0.868810  \n",
       "252            0.970722  \n",
       "253            1.293797  \n",
       "254            1.431960  \n",
       "255            3.890901  \n",
       "\n",
       "[256 rows x 27 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "lsvc = LinearSVC(C=0.3, penalty=\"l2\", dual=False).fit(x_scaled, y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "feature_idx = model.get_support()\n",
    "feature_name = x_scaled.columns[feature_idx]\n",
    "\n",
    "x_features_selected = model.transform(x_scaled)\n",
    "\n",
    "x_features_selected = pd.DataFrame(x_features_selected, columns=feature_name)\n",
    "\n",
    "x_features_selected.shape\n",
    "x_features_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "clear-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_features_selected, y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "legendary-knock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC accuracy :  0.8269230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\louis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "c:\\users\\louis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "SVM = svm.LinearSVC()\n",
    "SVM.fit(X_train, y_train)\n",
    "u=SVM.predict(X_test)\n",
    "print(\"LinearSVC accuracy : \" , accuracy_score(u, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-serum",
   "metadata": {},
   "source": [
    "## La selection de features avec un C de 0.3 nous a selectionné 27 colonnes et ne nous a pas aidé à améliorer nos performances\n",
    "\n",
    "## Notre résultat final est donc 0.9038461538461539"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cardiovascular-oasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "athletic-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "existing-officer",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC accuracy :  0.9038461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\louis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "SVM = svm.LinearSVC()\n",
    "SVM.fit(X_train, y_train)\n",
    "u=SVM.predict(X_test)\n",
    "print(\"LinearSVC accuracy : \" , accuracy_score(u, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "married-hepatitis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 2, 2, 1, 0, 2, 2, 3, 1, 3, 1, 0, 2, 2, 0, 1, 1, 1, 0, 1, 0,\n",
       "       2, 2, 2, 2, 1, 0, 2, 1, 0, 0, 3, 3, 2, 1, 2, 0, 2, 2, 2, 2, 3, 1,\n",
       "       0, 0, 1, 1, 0, 2, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "gross-buddy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chroma_0_mean</th>\n",
       "      <th>chroma_0_std</th>\n",
       "      <th>chroma_10_mean</th>\n",
       "      <th>chroma_10_std</th>\n",
       "      <th>chroma_11_mean</th>\n",
       "      <th>chroma_11_std</th>\n",
       "      <th>chroma_1_mean</th>\n",
       "      <th>chroma_1_std</th>\n",
       "      <th>chroma_2_mean</th>\n",
       "      <th>chroma_2_std</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_9_mean</th>\n",
       "      <th>mfcc_9_std</th>\n",
       "      <th>onset_rate</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_decrease_mean</th>\n",
       "      <th>spectral_flux_mean</th>\n",
       "      <th>spectral_rolloff_mean</th>\n",
       "      <th>spectral_spread_mean</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>zcr_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>232.907440</td>\n",
       "      <td>350.553833</td>\n",
       "      <td>206.571701</td>\n",
       "      <td>331.046967</td>\n",
       "      <td>225.048828</td>\n",
       "      <td>347.441132</td>\n",
       "      <td>221.465195</td>\n",
       "      <td>332.978180</td>\n",
       "      <td>224.200668</td>\n",
       "      <td>347.038422</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138428</td>\n",
       "      <td>0.572161</td>\n",
       "      <td>8.366616</td>\n",
       "      <td>56.939299</td>\n",
       "      <td>0.046856</td>\n",
       "      <td>1.796432</td>\n",
       "      <td>472.807018</td>\n",
       "      <td>2692.618591</td>\n",
       "      <td>163.125244</td>\n",
       "      <td>115.239277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>342.126831</td>\n",
       "      <td>615.817993</td>\n",
       "      <td>447.988678</td>\n",
       "      <td>562.143860</td>\n",
       "      <td>413.652649</td>\n",
       "      <td>633.503174</td>\n",
       "      <td>432.197021</td>\n",
       "      <td>668.721008</td>\n",
       "      <td>359.124786</td>\n",
       "      <td>426.877014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132142</td>\n",
       "      <td>0.684787</td>\n",
       "      <td>4.198134</td>\n",
       "      <td>23.288761</td>\n",
       "      <td>-0.022325</td>\n",
       "      <td>1.785995</td>\n",
       "      <td>1310.964912</td>\n",
       "      <td>1230.997277</td>\n",
       "      <td>170.899800</td>\n",
       "      <td>113.006177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92.768356</td>\n",
       "      <td>232.246658</td>\n",
       "      <td>152.421188</td>\n",
       "      <td>268.086456</td>\n",
       "      <td>79.888550</td>\n",
       "      <td>135.265106</td>\n",
       "      <td>75.790894</td>\n",
       "      <td>156.143219</td>\n",
       "      <td>148.015030</td>\n",
       "      <td>304.408112</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225053</td>\n",
       "      <td>0.602654</td>\n",
       "      <td>0.866282</td>\n",
       "      <td>20.381682</td>\n",
       "      <td>-0.263736</td>\n",
       "      <td>0.476780</td>\n",
       "      <td>1031.578947</td>\n",
       "      <td>1006.524430</td>\n",
       "      <td>81.420967</td>\n",
       "      <td>69.912374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>219.882584</td>\n",
       "      <td>410.804382</td>\n",
       "      <td>199.726151</td>\n",
       "      <td>305.265564</td>\n",
       "      <td>452.057037</td>\n",
       "      <td>1210.232788</td>\n",
       "      <td>321.175476</td>\n",
       "      <td>815.782837</td>\n",
       "      <td>408.686401</td>\n",
       "      <td>698.333984</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.261579</td>\n",
       "      <td>0.970925</td>\n",
       "      <td>1.965793</td>\n",
       "      <td>32.093015</td>\n",
       "      <td>-0.157930</td>\n",
       "      <td>0.866502</td>\n",
       "      <td>1332.456140</td>\n",
       "      <td>912.472403</td>\n",
       "      <td>148.232375</td>\n",
       "      <td>65.696249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>215.454269</td>\n",
       "      <td>306.737244</td>\n",
       "      <td>259.520355</td>\n",
       "      <td>343.783783</td>\n",
       "      <td>305.393311</td>\n",
       "      <td>368.144043</td>\n",
       "      <td>238.357651</td>\n",
       "      <td>349.670929</td>\n",
       "      <td>203.332275</td>\n",
       "      <td>340.900879</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130924</td>\n",
       "      <td>0.526003</td>\n",
       "      <td>4.298090</td>\n",
       "      <td>59.155876</td>\n",
       "      <td>-0.025128</td>\n",
       "      <td>1.741103</td>\n",
       "      <td>1482.894737</td>\n",
       "      <td>4637.320310</td>\n",
       "      <td>225.845447</td>\n",
       "      <td>110.317563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>378.110657</td>\n",
       "      <td>910.296631</td>\n",
       "      <td>411.037994</td>\n",
       "      <td>738.624512</td>\n",
       "      <td>474.921844</td>\n",
       "      <td>1271.251221</td>\n",
       "      <td>370.271271</td>\n",
       "      <td>974.712097</td>\n",
       "      <td>224.349991</td>\n",
       "      <td>471.294678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543129</td>\n",
       "      <td>0.572005</td>\n",
       "      <td>2.099067</td>\n",
       "      <td>12.647468</td>\n",
       "      <td>-0.208215</td>\n",
       "      <td>1.337591</td>\n",
       "      <td>838.157895</td>\n",
       "      <td>304.780476</td>\n",
       "      <td>83.854556</td>\n",
       "      <td>86.154190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>298.790619</td>\n",
       "      <td>838.457458</td>\n",
       "      <td>289.558838</td>\n",
       "      <td>651.673340</td>\n",
       "      <td>285.266571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220.631119</td>\n",
       "      <td>451.879761</td>\n",
       "      <td>316.052155</td>\n",
       "      <td>772.024902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024739</td>\n",
       "      <td>0.658864</td>\n",
       "      <td>3.098623</td>\n",
       "      <td>9.447293</td>\n",
       "      <td>-0.562238</td>\n",
       "      <td>1.568547</td>\n",
       "      <td>322.368421</td>\n",
       "      <td>1445.712302</td>\n",
       "      <td>192.579308</td>\n",
       "      <td>185.982475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>340.823334</td>\n",
       "      <td>581.847351</td>\n",
       "      <td>229.372055</td>\n",
       "      <td>268.090668</td>\n",
       "      <td>237.591629</td>\n",
       "      <td>272.746857</td>\n",
       "      <td>344.910767</td>\n",
       "      <td>481.311584</td>\n",
       "      <td>325.790955</td>\n",
       "      <td>439.735168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337493</td>\n",
       "      <td>0.447563</td>\n",
       "      <td>5.530875</td>\n",
       "      <td>5.660125</td>\n",
       "      <td>-0.490255</td>\n",
       "      <td>0.952766</td>\n",
       "      <td>128.947368</td>\n",
       "      <td>505.899176</td>\n",
       "      <td>111.885235</td>\n",
       "      <td>75.096457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>461.047760</td>\n",
       "      <td>662.166565</td>\n",
       "      <td>NaN</td>\n",
       "      <td>593.540649</td>\n",
       "      <td>493.840912</td>\n",
       "      <td>541.830078</td>\n",
       "      <td>508.564453</td>\n",
       "      <td>568.137085</td>\n",
       "      <td>1304.457153</td>\n",
       "      <td>1389.750732</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117043</td>\n",
       "      <td>0.470288</td>\n",
       "      <td>6.186056</td>\n",
       "      <td>33.860030</td>\n",
       "      <td>0.005855</td>\n",
       "      <td>1.481684</td>\n",
       "      <td>1418.421053</td>\n",
       "      <td>1286.331697</td>\n",
       "      <td>233.868235</td>\n",
       "      <td>129.624790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>639.218750</td>\n",
       "      <td>1713.408691</td>\n",
       "      <td>371.654480</td>\n",
       "      <td>708.324524</td>\n",
       "      <td>434.294373</td>\n",
       "      <td>748.698120</td>\n",
       "      <td>358.546112</td>\n",
       "      <td>960.213440</td>\n",
       "      <td>200.575485</td>\n",
       "      <td>351.556396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253356</td>\n",
       "      <td>1.221632</td>\n",
       "      <td>6.130609</td>\n",
       "      <td>23.056672</td>\n",
       "      <td>-0.033953</td>\n",
       "      <td>1.828413</td>\n",
       "      <td>1074.561404</td>\n",
       "      <td>666.447737</td>\n",
       "      <td>131.552930</td>\n",
       "      <td>109.372880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    chroma_0_mean  chroma_0_std  chroma_10_mean  chroma_10_std  \\\n",
       "0      232.907440    350.553833      206.571701     331.046967   \n",
       "1      342.126831    615.817993      447.988678     562.143860   \n",
       "2       92.768356    232.246658      152.421188     268.086456   \n",
       "3      219.882584    410.804382      199.726151     305.265564   \n",
       "4      215.454269    306.737244      259.520355     343.783783   \n",
       "..            ...           ...             ...            ...   \n",
       "75     378.110657    910.296631      411.037994     738.624512   \n",
       "76     298.790619    838.457458      289.558838     651.673340   \n",
       "77     340.823334    581.847351      229.372055     268.090668   \n",
       "78     461.047760    662.166565             NaN     593.540649   \n",
       "79     639.218750   1713.408691      371.654480     708.324524   \n",
       "\n",
       "    chroma_11_mean  chroma_11_std  chroma_1_mean  chroma_1_std  chroma_2_mean  \\\n",
       "0       225.048828     347.441132     221.465195    332.978180     224.200668   \n",
       "1       413.652649     633.503174     432.197021    668.721008     359.124786   \n",
       "2        79.888550     135.265106      75.790894    156.143219     148.015030   \n",
       "3       452.057037    1210.232788     321.175476    815.782837     408.686401   \n",
       "4       305.393311     368.144043     238.357651    349.670929     203.332275   \n",
       "..             ...            ...            ...           ...            ...   \n",
       "75      474.921844    1271.251221     370.271271    974.712097     224.349991   \n",
       "76      285.266571            NaN     220.631119    451.879761     316.052155   \n",
       "77      237.591629     272.746857     344.910767    481.311584     325.790955   \n",
       "78      493.840912     541.830078     508.564453    568.137085    1304.457153   \n",
       "79      434.294373     748.698120     358.546112    960.213440     200.575485   \n",
       "\n",
       "    chroma_2_std  ...  mfcc_9_mean  mfcc_9_std  onset_rate  \\\n",
       "0     347.038422  ...    -0.138428    0.572161    8.366616   \n",
       "1     426.877014  ...     0.132142    0.684787    4.198134   \n",
       "2     304.408112  ...    -0.225053    0.602654    0.866282   \n",
       "3     698.333984  ...    -0.261579    0.970925    1.965793   \n",
       "4     340.900879  ...    -0.130924    0.526003    4.298090   \n",
       "..           ...  ...          ...         ...         ...   \n",
       "75    471.294678  ...     0.543129    0.572005    2.099067   \n",
       "76    772.024902  ...     0.024739    0.658864    3.098623   \n",
       "77    439.735168  ...     0.337493    0.447563    5.530875   \n",
       "78   1389.750732  ...    -0.117043    0.470288    6.186056   \n",
       "79    351.556396  ...     0.253356    1.221632    6.130609   \n",
       "\n",
       "    spectral_centroid_mean  spectral_decrease_mean  spectral_flux_mean  \\\n",
       "0                56.939299                0.046856            1.796432   \n",
       "1                23.288761               -0.022325            1.785995   \n",
       "2                20.381682               -0.263736            0.476780   \n",
       "3                32.093015               -0.157930            0.866502   \n",
       "4                59.155876               -0.025128            1.741103   \n",
       "..                     ...                     ...                 ...   \n",
       "75               12.647468               -0.208215            1.337591   \n",
       "76                9.447293               -0.562238            1.568547   \n",
       "77                5.660125               -0.490255            0.952766   \n",
       "78               33.860030                0.005855            1.481684   \n",
       "79               23.056672               -0.033953            1.828413   \n",
       "\n",
       "    spectral_rolloff_mean  spectral_spread_mean    zcr_mean     zcr_std  \n",
       "0              472.807018           2692.618591  163.125244  115.239277  \n",
       "1             1310.964912           1230.997277  170.899800  113.006177  \n",
       "2             1031.578947           1006.524430   81.420967   69.912374  \n",
       "3             1332.456140            912.472403  148.232375   65.696249  \n",
       "4             1482.894737           4637.320310  225.845447  110.317563  \n",
       "..                    ...                   ...         ...         ...  \n",
       "75             838.157895            304.780476   83.854556   86.154190  \n",
       "76             322.368421           1445.712302  192.579308  185.982475  \n",
       "77             128.947368            505.899176  111.885235   75.096457  \n",
       "78            1418.421053           1286.331697  233.868235  129.624790  \n",
       "79            1074.561404            666.447737  131.552930  109.372880  \n",
       "\n",
       "[80 rows x 61 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-section",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "personalized-process",
   "metadata": {},
   "source": [
    "## Ce que j'aurais souhaité faire avec plus de temps : \n",
    "#### - Tester mes performances si je change la proportion du jeu de test, ici nous prenons 80% de 256 lignes pour nous entrainer, peux-etre qu'avec 90 voir 95 % nous aurons des mauvaises performances sur le jeu de train mais de meilleures sur celui de test\n",
    "#### - Retirer moins d'outliers pour avoir plus de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-andrew",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "backed-technician",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "lightweight-toyota",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "traditional-passion",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\louis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM = svm.LinearSVC()\n",
    "SVM.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "medical-mexican",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nous remplacçons les valeurs NA via le KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "df_test= pd.DataFrame(imputer.fit_transform(df_test), columns=df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "indonesian-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = scaler.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "minute-circulation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 0, 2, 1, 2, 2, 1, 2, 0, 2, 2, 1, 1, 3, 1, 3, 3, 3, 1, 1,\n",
       "       1, 0, 3, 2, 0, 0, 3, 2, 1, 2, 0, 0, 1, 1, 0, 0, 3, 3, 2, 3, 2, 1,\n",
       "       3, 1, 1, 0, 3, 0, 3, 0, 2, 2, 2, 3, 3, 1, 0, 2, 3, 2, 0, 3, 1, 1,\n",
       "       1, 1, 0, 2, 0, 2, 1, 2, 2, 1, 1, 3, 0, 3], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = SVM.predict(df_test)\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "straight-empire",
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = pd.DataFrame({'music_id': test_id, 'category': test_predictions})\n",
    "solutions.to_csv('C:/Users/Louis/Desktop/ML_Elective.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
